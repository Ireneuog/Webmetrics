{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc49300",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e829a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import schedule\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, Toplevel\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from sqlite3 import connect\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1819dd6",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49f6c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyB1yXwbkMUH_00Ixj-ztWQyGtCAzEYxMRY\"\n",
    "CX = \"c122f8bd52e10465a\"\n",
    "DB_NAME = 'webmetrics.db'\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8a924",
   "metadata": {},
   "source": [
    "#### Criar Database (não rodar se á houver uma database criada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2aa4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_base_dados():\n",
    "    with connect(DB_NAME) as conn:\n",
    "        conn.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS webmetrics (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                query TEXT,\n",
    "                url TEXT,\n",
    "                words INTEGER,\n",
    "                stopwords INTEGER,\n",
    "                midias INTEGER,\n",
    "                percText REAL,\n",
    "                pageSize REAL,\n",
    "                lexDensity REAL,\n",
    "                nouns INTEGER,\n",
    "                verbs INTEGER,\n",
    "                adverbs INTEGER,\n",
    "                adjectives INTEGER\n",
    "            )\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b94f1",
   "metadata": {},
   "source": [
    "#### Limpar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486dfde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto(texto):\n",
    "    return re.sub(r'\\s+', ' ', texto).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10bc718",
   "metadata": {},
   "source": [
    "#### Densidade lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a093597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densidade_lexical(texto):\n",
    "    tokens = word_tokenize(texto)\n",
    "    palavras = [t.lower() for t in tokens if t.isalpha()]\n",
    "    return round(len(set(palavras)) / len(palavras), 2) if palavras else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0acb2f9",
   "metadata": {},
   "source": [
    "### Analisar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e35d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analisar_texto_nltk(texto):\n",
    "    tokens = word_tokenize(texto)\n",
    "    palavras = [t for t in tokens if t.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stopword_tokens = [t for t in palavras if t.lower() in stop_words]\n",
    "    tagged = pos_tag(palavras)\n",
    "\n",
    "    categorias = {\n",
    "        'NOMES': [], 'SUBSTANTIVOS': [], 'VERBOS': [], 'ADJETIVOS': [], 'ADVÉRBIOS': []\n",
    "    }\n",
    "\n",
    "    for palavra, tag in tagged:\n",
    "        if tag.startswith('NNP'): categorias['NOMES'].append(palavra)\n",
    "        elif tag.startswith('NN'): categorias['SUBSTANTIVOS'].append(palavra)\n",
    "        elif tag.startswith('VB'): categorias['VERBOS'].append(palavra)\n",
    "        elif tag.startswith('JJ'): categorias['ADJETIVOS'].append(palavra)\n",
    "        elif tag.startswith('RB'): categorias['ADVÉRBIOS'].append(palavra)\n",
    "\n",
    "    return {\n",
    "        'frequencias': {cat: Counter(words).most_common(5) for cat, words in categorias.items()},\n",
    "        'totais': {\n",
    "            'NOMES': len(categorias['NOMES']),\n",
    "            'SUBSTANTIVOS': len(categorias['SUBSTANTIVOS']),\n",
    "            'VERBOS': len(categorias['VERBOS']),\n",
    "            'ADJETIVOS': len(categorias['ADJETIVOS']),\n",
    "            'ADVÉRBIOS': len(categorias['ADVÉRBIOS']),\n",
    "            'STOPWORDS': len(stopword_tokens)\n",
    "        },\n",
    "        'categorias': categorias\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65adef28",
   "metadata": {},
   "source": [
    "### Escolher termo aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd3046bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escolher_termo_aleatorio():\n",
    "    termos = [lemma.name().replace('_', ' ').lower() for syn in wn.all_synsets(pos=wn.NOUN)\n",
    "              for lemma in syn.lemmas() if lemma.name().isalpha() and len(lemma.name()) >= 4]\n",
    "    return random.choice(termos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc28a13",
   "metadata": {},
   "source": [
    "### Analisar pagina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "565d102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_pagina(url):\n",
    "    try:\n",
    "        resposta = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        resposta.raise_for_status()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(resposta.text, 'html.parser')\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "    texto = limpar_texto(soup.get_text())\n",
    "\n",
    "    if not texto or len(texto.split()) < 30:\n",
    "        return None\n",
    "\n",
    "    num_palavras = len(texto.split())\n",
    "    num_imagens = len(soup.find_all('img'))\n",
    "    num_videos = len(soup.find_all(['video', 'iframe']))\n",
    "    tamanho_texto_kb = round(len(texto.encode('utf-8')) / 1024, 2)\n",
    "    tamanho_total_kb = round(len(resposta.content) / 1024, 2)\n",
    "    percentual_texto = round((tamanho_texto_kb / tamanho_total_kb) * 100, 2) if tamanho_total_kb else 0\n",
    "\n",
    "    analise = analisar_texto_nltk(texto)\n",
    "\n",
    "    return {\n",
    "        'url': url,\n",
    "        'n_palavras': num_palavras,\n",
    "        'n_imagens': num_imagens,\n",
    "        'n_videos': num_videos,\n",
    "        'tamanho_texto_kb': tamanho_texto_kb,\n",
    "        'tamanho_total_kb': tamanho_total_kb,\n",
    "        'percentual_texto': percentual_texto,\n",
    "        'densidade_lexical': densidade_lexical(texto),\n",
    "        'total_stopwords': analise['totais']['STOPWORDS'],\n",
    "        'total_nouns': analise['totais']['SUBSTANTIVOS'],\n",
    "        'total_verbs': analise['totais']['VERBOS'],\n",
    "        'total_adjectives': analise['totais']['ADJETIVOS'],\n",
    "        'total_adverbs': analise['totais']['ADVÉRBIOS'],\n",
    "        'analise_linguistica': analise,\n",
    "        'texto': texto\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c3dbb",
   "metadata": {},
   "source": [
    "### Buscar links atraves da API do google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be7fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_links_google(query):\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\"key\": API_KEY, \"cx\": CX, \"q\": query, \"num\": 10, \"start\": random.randint(1, 90)}\n",
    "    r = requests.get(url, params=params)\n",
    "    if r.status_code == 200:\n",
    "        return [item['link'] for item in r.json().get('items', [])]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4052e9a",
   "metadata": {},
   "source": [
    "#### Salvar resultados na database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1edab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_em_db(resultados):\n",
    "    with connect(DB_NAME) as conn:\n",
    "        for r in resultados:\n",
    "            try:\n",
    "                conn.execute('''\n",
    "                    INSERT INTO webmetrics (query, url, words, stopwords, midias, percText, pageSize, lexDensity, nouns, verbs, adverbs, adjectives)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''', (\n",
    "                    r.get('query'), r['url'], r['n_palavras'], r['total_stopwords'],\n",
    "                    r['n_imagens'] + r['n_videos'], r['percentual_texto'],\n",
    "                    r['tamanho_total_kb'], r['densidade_lexical'],\n",
    "                    r['total_nouns'], r['total_verbs'],\n",
    "                    r['total_adverbs'], r['total_adjectives']\n",
    "                ))\n",
    "            except Exception as e:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c2bbd",
   "metadata": {},
   "source": [
    "#### Visualização dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "636b8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_resultados(resultados):\n",
    "    urls = [r['url'] for r in resultados]\n",
    "    texto_pct = [r['percentual_texto'] for r in resultados]\n",
    "    num_palavras = [r['n_palavras'] for r in resultados]\n",
    "    num_midias = [r['n_imagens'] + r['n_videos'] for r in resultados]\n",
    "    dens_lex = [r['densidade_lexical'] for r in resultados]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.barh(urls, texto_pct)\n",
    "    plt.xlabel('% de Texto na Página')\n",
    "    plt.title('Distribuição da Percentagem de Texto')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(num_palavras, num_midias)\n",
    "    plt.xlabel('Número de Palavras')\n",
    "    plt.ylabel('Número de Mídias')\n",
    "    plt.title('Correlação entre Texto e Mídia')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.barh(urls, dens_lex)\n",
    "    plt.xlabel('Densidade Lexical')\n",
    "    plt.title('Densidade Lexical por Página')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83525a3",
   "metadata": {},
   "source": [
    "### Interface gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6dfebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebMetricsGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"WebMetrics\")\n",
    "        self.root.geometry(\"600x500\")\n",
    "        # Fonte e estilo\n",
    "        self.style = ttk.Style()\n",
    "        self.style.configure(\"TButton\", font=(\"Helvetica\", 10), padding=8)\n",
    "        self.style.configure(\"TLabel\", font=(\"Helvetica\", 12))\n",
    "        self.style.configure(\"Header.TLabel\", font=(\"Helvetica\", 16, \"bold\"))\n",
    "        \n",
    "        self.resultados = []\n",
    "        # --- Título ---\n",
    "        header = ttk.Label(root, text=\"WebMetrics\", style=\"Header.TLabel\")\n",
    "        header.pack(pady=(20,10))\n",
    "        \n",
    "        # --- Frame para botões ---\n",
    "        btn_frame = ttk.Frame(root)\n",
    "        btn_frame.pack(pady=10)\n",
    "        \n",
    "        # Botões alinhados e tamanho único\n",
    "        btn_opts = {\"master\": btn_frame, \"width\": 20}\n",
    "        self.btn_random = ttk.Button(**btn_opts, text=\"Pesquisa Aleatória\", command=self.pesquisa_aleatoria)\n",
    "        self.btn_schedule = ttk.Button(**btn_opts, text=\"Fazer Agendamento\", command=self.janela_agendamento)\n",
    "        self.btn_stop = ttk.Button(**btn_opts, text=\"Parar Agendamento\", command=self.parar_agendamento)\n",
    "        self.btn_view_recent = ttk.Button(**btn_opts, text=\"Gráficos da pesquisa\", command=self.mostrar_graficos)\n",
    "        self.btn_view_db = ttk.Button(**btn_opts, text=\"Gráficos da BD\", command=self.mostrar_graficos_db)\n",
    "        self.btn_db = ttk.Button(**btn_opts, text=\"Ver Base de Dados\", command=self.ver_db)\n",
    "        \n",
    "        self.log = tk.Text(root, height=10, width=80)\n",
    "        self.log.pack(pady=10)\n",
    "        self.log.config(state=\"disabled\")  # se quiseres evitar edição direta\n",
    "\n",
    "        \n",
    "        # Grid dentro do frame\n",
    "        for i, btn in enumerate([self.btn_random, self.btn_schedule, self.btn_view_recent, self.btn_stop,\n",
    "                                 self.btn_view_db, self.btn_db]):\n",
    "            btn.grid(row=i//2, column=i%2, padx=10, pady=5, sticky=\"ew\")\n",
    "        \n",
    "    def mostrar_graficos_db(self):\n",
    "        # Carrega todos os registos da BD\n",
    "        with connect(DB_NAME) as conn:\n",
    "            df = pd.read_sql_query(\n",
    "                \"SELECT url, percText, words AS n_palavras, midias, lexDensity AS densidade_lexical \"\n",
    "                \"FROM webmetrics\",\n",
    "                conn\n",
    "            )\n",
    "\n",
    "        if df.empty:\n",
    "            messagebox.showinfo(\"Info\", \"Nenhum dado na base de dados para visualização.\")\n",
    "            return\n",
    "\n",
    "        # 0) Índices e labels\n",
    "        indices = list(range(len(df)))\n",
    "\n",
    "        # Ajuste 1: garante 0 ≤ percText ≤ 100\n",
    "        df[\"percText_clipped\"] = df[\"percText\"].clip(lower=0, upper=100)\n",
    "\n",
    "        # 1) Scatter da percentagem de texto\n",
    "        plt.figure()\n",
    "        plt.scatter(indices, df[\"percText_clipped\"], marker='o')\n",
    "        plt.ylim(0, 100)\n",
    "        plt.xlabel(\"Páginas\")\n",
    "        plt.ylabel(\"% de Texto\")\n",
    "        plt.title(\"Distribuição da Percentagem de Texto\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 2) Scatter do número de palavras vs número de mídias\n",
    "        plt.figure()\n",
    "        plt.scatter(df[\"n_palavras\"], df[\"midias\"], marker='o')\n",
    "        plt.xlim(0, 10000)  # Ajuste 2: número de palavras limitado a 10 000\n",
    "        plt.xlabel(\"Número de Palavras\")\n",
    "        plt.ylabel(\"Número de Mídias\")\n",
    "        plt.title(\"Correlação entre Texto e Mídia (corte em 10 000 palavras)\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 3) Scatter da densidade lexical\n",
    "        plt.figure()\n",
    "        plt.scatter(indices, df[\"densidade_lexical\"], marker='o')\n",
    "        plt.xlabel(\"Páginas\")\n",
    "        plt.ylabel(\"Densidade Lexical\")\n",
    "        plt.title(\"Distribuição da Densidade Lexical (Scatter)\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def log_msg(self, msg):\n",
    "        timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n",
    "        self.log.insert(tk.END, f\"{timestamp} {msg}\\n\")\n",
    "        self.log.see(tk.END)\n",
    "\n",
    "    def pesquisa_aleatoria(self):\n",
    "        termo = escolher_termo_aleatorio()\n",
    "        self.log_msg(f\" A pesquisar: {termo}\")\n",
    "        links = buscar_links_google(termo)\n",
    "        resultados = []\n",
    "        for link in links:\n",
    "            res = analisar_pagina(link)\n",
    "            if res:\n",
    "                res['query'] = termo\n",
    "                resultados.append(res)\n",
    "                self.log_msg(f\"→ {link} | Palavras: {res['n_palavras']} | Stopwords: {res['total_stopwords']} | Densidade: {res['densidade_lexical']}\")\n",
    "            time.sleep(1)\n",
    "        if resultados:\n",
    "            salvar_em_db(resultados)\n",
    "            self.resultados = resultados\n",
    "            self.log_msg(\" Resultados guardados.\")\n",
    "        else:\n",
    "            self.log_msg(\" Nenhum resultado relevante.\")\n",
    "\n",
    "    def janela_agendamento(self):\n",
    "        janela = Toplevel(self.root)\n",
    "        janela.title(\"Configurar Agendamento\")\n",
    "\n",
    "        ttk.Label(janela, text=\"Pesquisas por Dia:\").grid(row=0, column=0)\n",
    "        ttk.Label(janela, text=\"Pesquisas por Hora:\").grid(row=1, column=0)\n",
    "\n",
    "        dia_entry = ttk.Entry(janela)\n",
    "        hora_entry = ttk.Entry(janela)\n",
    "        dia_entry.grid(row=0, column=1)\n",
    "        hora_entry.grid(row=1, column=1)\n",
    "\n",
    "        def iniciar():\n",
    "            try:\n",
    "                por_dia = int(dia_entry.get())\n",
    "                por_hora = int(hora_entry.get())\n",
    "                intervalo = int(60 / por_hora)\n",
    "                max_dia = 24 * por_hora\n",
    "                if por_dia > max_dia:\n",
    "                    self.log_msg(f\" Máximo permitido: {max_dia} por dia. Ajustado automaticamente.\")\n",
    "                    por_dia = max_dia\n",
    "                self.total_pedidas = por_dia\n",
    "                self.pesquisas_feitas = 0\n",
    "                self.inicio = datetime.now()\n",
    "                self.fim = self.inicio + timedelta(minutes=intervalo * por_dia)\n",
    "\n",
    "                def tarefa():\n",
    "                    if self.pesquisas_feitas >= por_dia:\n",
    "                        return schedule.CancelJob\n",
    "                    termo = escolher_termo_aleatorio()\n",
    "                    self.log_msg(f\" [{self.pesquisas_feitas + 1}] {termo}\")\n",
    "                    resultados = []\n",
    "                    links = buscar_links_google(termo)\n",
    "                    for link in links:\n",
    "                        res = analisar_pagina(link)\n",
    "                        if res:\n",
    "                            res['query'] = termo\n",
    "                            resultados.append(res)\n",
    "                        time.sleep(1)\n",
    "                    if resultados:\n",
    "                        salvar_em_db(resultados)\n",
    "                        self.resultados.extend(resultados)\n",
    "                    self.pesquisas_feitas += 1\n",
    "\n",
    "                schedule.every(intervalo).minutes.do(tarefa)\n",
    "\n",
    "                def run_schedule():\n",
    "                    while self.pesquisas_feitas < self.total_pedidas:\n",
    "                        schedule.run_pending()\n",
    "                        time.sleep(1)\n",
    "                    self.log_msg(\" Agendamento concluído.\")\n",
    "\n",
    "                self.task_thread = Thread(target=run_schedule, daemon=True)\n",
    "                self.task_thread.start()\n",
    "                self.log_msg(\" Agendamento iniciado...\")\n",
    "                janela.destroy()\n",
    "\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Erro\", str(e))\n",
    "\n",
    "        ttk.Button(janela, text=\"Iniciar\", command=iniciar).grid(row=2, column=0, columnspan=2, pady=10)\n",
    "    \n",
    "    def parar_agendamento(self):\n",
    "        schedule.clear()\n",
    "        self.pesquisas_feitas = 0\n",
    "        self.log_msg(\" Qualquer tarefa ativa foi parada.\")\n",
    "\n",
    "    def ver_db(self):\n",
    "        janela = Toplevel(self.root)\n",
    "        janela.title(\"Base de Dados\")\n",
    "        tree = ttk.Treeview(janela)\n",
    "        tree.pack(fill='both', expand=True)\n",
    "\n",
    "        with connect(DB_NAME) as conn:\n",
    "            df = pd.read_sql_query(\"SELECT * FROM webmetrics\", conn)\n",
    "\n",
    "        tree['columns'] = list(df.columns)\n",
    "        tree['show'] = 'headings'\n",
    "\n",
    "        for col in df.columns:\n",
    "            tree.heading(col, text=col)\n",
    "            tree.column(col, width=100)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            tree.insert(\"\", tk.END, values=list(row))\n",
    "\n",
    "    def mostrar_graficos(self):\n",
    "        if not self.resultados:\n",
    "            messagebox.showinfo(\"Info\", \"Nenhum resultado recente para visualização.\")\n",
    "            return\n",
    "\n",
    "        urls = [r['url'] for r in self.resultados]\n",
    "        urls_legiveis = [url[:60] + \"...\" if len(url) > 60 else url for url in urls]\n",
    "\n",
    "        # Corrigir cálculo de percentagem de texto para garantir intervalo 0-100% e evitar distorções\n",
    "        texto_pct = []\n",
    "        for r in self.resultados:\n",
    "            total_kb = r['tamanho_total_kb']\n",
    "            texto_kb = r['tamanho_texto_kb']\n",
    "            if total_kb > 0:\n",
    "                pct = (texto_kb / total_kb) * 100\n",
    "                pct = max(0, min(pct, 100))  # garantir dentro de 0 a 100%\n",
    "            else:\n",
    "                pct = 0\n",
    "            texto_pct.append(round(pct, 2))\n",
    "\n",
    "        num_palavras = [r['n_palavras'] for r in self.resultados]\n",
    "        num_midias = [r['n_imagens'] + r['n_videos'] for r in self.resultados]\n",
    "        dens_lex = [r['densidade_lexical'] for r in self.resultados]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.barh(urls_legiveis, texto_pct)\n",
    "        plt.xlabel('% de Texto na Página')\n",
    "        plt.title('Distribuição da Percentagem de Texto')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.scatter(num_palavras, num_midias, c='blue')\n",
    "        plt.xlabel('Número de Palavras')\n",
    "        plt.ylabel('Número de Mídias')\n",
    "        plt.title('Correlação entre Texto e Mídia')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.barh(urls_legiveis, dens_lex, color='green')\n",
    "        plt.xlabel('Densidade Lexical')\n",
    "        plt.title('Densidade Lexical por Página')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cb107",
   "metadata": {},
   "source": [
    "#### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef188c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = WebMetricsGUI(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
